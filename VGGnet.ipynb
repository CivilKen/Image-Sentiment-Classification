{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_v4.ipnb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CivilKen/Image-Sentiment-Classification/blob/master/VGGnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfIoS3Wb4Ati",
        "colab_type": "code",
        "outputId": "d052dedc-60cf-4c5d-c676-eee33c9cb9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "!ls \"/content/gdrive/My Drive/ML_homework/Colab Notebooks/hw3\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            " df_test_feature   'hw3_v3.ipnb '\t      nor_df_valid_feature\n",
            " df_train_feature   hw3_v4.ipnb\t\t      ParseData.ipynb\n",
            " df_train_label    'hw3_v4.ipnb 的副本 (1)'   StoredModel\n",
            " df_valid_feature   hw3_v4_restore.ipnb       test.csv\n",
            " df_valid_label     hw3_v5.ipnb\t\t      test_feature.csv\n",
            " hw3_v1.ipynb\t    nor_df_test_feature       train.csv\n",
            " hw3_v2.ipynb\t    nor_df_train_feature      train_feature.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH7SGefu4GGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from skimage import io \n",
        "import matplotlib.pyplot as plt\n",
        "path = \"/content/gdrive/My Drive/ML_homework/Colab Notebooks/hw3/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lYGKrp9hmOB",
        "colab_type": "code",
        "outputId": "453dbd27-e3da-4568-ae82-740e570a9a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#test GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvANH94h4PEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read dataframe \n",
        "df_train_feature = pd.read_pickle(path+\"df_train_feature\")\n",
        "df_valid_feature = pd.read_pickle(path+\"df_valid_feature\")\n",
        "df_test_feature = pd.read_pickle(path+\"df_test_feature\")\n",
        "df_train_label = pd.read_pickle(path+\"df_train_label\")\n",
        "df_valid_label = pd.read_pickle(path+\"df_valid_label\")\n",
        "nor_df_train_feature = pd.read_pickle(path+\"nor_df_train_feature\")\n",
        "nor_df_valid_feature = pd.read_pickle(path+\"nor_df_valid_feature\")\n",
        "nor_df_test_feature = pd.read_pickle(path+\"nor_df_test_feature\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1dRWLvY4Tgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parse label data\n",
        "def one_hot(df_label,lenth):\n",
        "  #original input is dataframe\n",
        "  array_label = np.zeros([lenth,7])\n",
        "  for i in range(lenth):\n",
        "    idx = df_label.loc[i]\n",
        "    array_label[i, idx]=1\n",
        "  return array_label\n",
        "\n",
        "arr_train_label = one_hot(df_train_label, df_train_label.shape[0])\n",
        "arr_valid_label = one_hot(df_valid_label, df_valid_label.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCGtl6UI4Xas",
        "colab_type": "code",
        "outputId": "d345f1b8-bea2-4e75-d073-f9f383a454f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "# define accuracy\n",
        "def accuracy(labels, pred):\n",
        "  #both labels and pred are in the shape of one-hot encoding\n",
        "  #both are in the format of array\n",
        "  accu=0\n",
        "  for i in range(len(labels)):\n",
        "    lab_val = np.argmax(labels[i,:])\n",
        "    pred_val = np.argmax(pred[i,:])\n",
        "    if lab_val==pred_val:\n",
        "      accu+=1\n",
        "  return accu/len(labels)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# define accuracy\\ndef accuracy(labels, pred):\\n  #both labels and pred are in the shape of one-hot encoding\\n  #both are in the format of array\\n  accu=0\\n  for i in range(len(labels)):\\n    lab_val = np.argmax(labels[i,:])\\n    pred_val = np.argmax(pred[i,:])\\n    if lab_val==pred_val:\\n      accu+=1\\n  return accu/len(labels)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLOdOkCW4sNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "InputNeurons = df_train_feature.shape[1]\n",
        "OutputNeurons = 7\n",
        "drop_rate = 0.6  # dropout parameter, drop how many percentage\n",
        "learning_rate = 0.0005\n",
        "beta = 0.001 #it's used in regularization as lamda\n",
        "printstep = 100\n",
        "traing_epochs = 50001\n",
        "\n",
        "# define placeholder for inputs to network\n",
        "rs = tf.placeholder(tf.float32) #drop rate\n",
        "xs = tf.placeholder(tf.float32, [None, InputNeurons])\n",
        "ys = tf.placeholder(tf.float32, [None, OutputNeurons])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaQ1_9BMryYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define hidden layer\n",
        "def dense(inputs, in_size, out_size, drop_rate, activation_function=None, Wname=None, banme=None):\n",
        "    # add one more layer and return the output of this layer\n",
        "    Weights = tf.Variable(tf.random_normal([in_size, out_size],stddev=0.01))\n",
        "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
        "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
        "    #Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
        "    if activation_function is None:\n",
        "        outputs = Wx_plus_b\n",
        "    elif activation_function=='maxout':\n",
        "        outputs = tf.contrib.layers.maxout(Wx_plus_b,out_size)\n",
        "    else:\n",
        "        outputs = activation_function(Wx_plus_b)\n",
        "    outputs = tf.nn.dropout(x=outputs, rate=drop_rate)\n",
        "    return outputs, Weights, biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb7TXHqvp640",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = tf.reshape(xs, [-1,48,48,1])\n",
        "conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[3,3], padding='same', activation=tf.nn.relu)#filter set to be [5,5]\n",
        "conv2 = tf.layers.conv2d(inputs=conv1, filters=32, kernel_size=[3,3], padding='same', activation=tf.nn.relu)\n",
        "pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2,2], strides=2)\n",
        "conv3 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3,3], padding='same', activation=tf.nn.relu)\n",
        "conv4 = tf.layers.conv2d(inputs=conv3, filters=64, kernel_size=[3,3], padding='same', activation=tf.nn.relu)\n",
        "pool2 = tf.layers.average_pooling2d(inputs=conv4, pool_size=[2,2], strides=2)\n",
        "conv5 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=[3,3], padding='same', activation=tf.nn.relu)\n",
        "conv6 = tf.layers.conv2d(inputs=conv5, filters=128, kernel_size=[3,3], padding='same', activation=tf.nn.relu)\n",
        "pool3 = tf.layers.average_pooling2d(inputs=conv6, pool_size=[2,2], strides=2)\n",
        "pool_flat = tf.reshape(pool3, [-1, 6*6*128])\n",
        "[dense1, w1, b1] = dense(pool_flat, 6*6*128, 1024, rs, activation_function=tf.nn.relu)\n",
        "[dense2, w2, b2] = dense(dense1, 1024, 512, rs, activation_function=tf.nn.relu)\n",
        "logits = tf.layers.dense(inputs=dense2, units=OutputNeurons)\n",
        "prediction = tf.nn.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Fl3ImbpbYOA",
        "outputId": "79b5306a-dc5a-4736-e07a-4d9a5a67e280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "#calculate loss function\n",
        "regularizers = tf.nn.l2_loss(w1)+tf.nn.l2_loss(w2)\n",
        "#loss = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), axis=1))\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=ys, logits=logits))\n",
        "loss = loss + beta*regularizers\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "# start of the neural network\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "TrainLoss=[]\n",
        "ValidLoss=[]\n",
        "epoch=[]\n",
        "for i in range(traing_epochs):\n",
        "    # training\n",
        "    idx = np.random.choice(np.arange(len(df_train_feature)), 64, replace=False)\n",
        "    x_train_batch = df_train_feature.loc[idx,:]\n",
        "    y_train_batch = arr_train_label[idx,:]\n",
        "    sess.run(train_step, feed_dict={xs: x_train_batch, ys: y_train_batch, rs: drop_rate})\n",
        "    if i % printstep == 0:\n",
        "        # to see the step improvement\n",
        "        train_loss = sess.run(loss, feed_dict={xs: x_train_batch, ys: y_train_batch, rs: 0})\n",
        "        validation_loss = sess.run(loss, feed_dict={xs: df_valid_feature, ys: arr_valid_label, rs:0})\n",
        "        print(\"epoch\",i,\"validation loss=\", validation_loss,\"Train Loss=\",train_loss)\n",
        "        TrainLoss.append(train_loss)\n",
        "        ValidLoss.append(validation_loss)\n",
        "        epoch.append(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 validation loss= 2.1083019 Train Loss= 2.0704026\n",
            "epoch 100 validation loss= 1.8357298 Train Loss= 1.9440422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3cd99c3fe241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_train_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdrop_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprintstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to see the step improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiTFEYJhCY_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% plot loss\n",
        "fig = plt.figure()\n",
        "# 111代表在subplot圖中的位置\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(epoch[1:], TrainLoss[1:], c='b', label='TrainLoss', linewidth=0.5)\n",
        "ax.plot(epoch[1:], ValidLoss[1:], c='r', label='ValidLoss', linewidth=0.5)\n",
        "leg = plt.legend()\n",
        "# get the lines and texts inside legend box\n",
        "leg_lines = leg.get_lines()\n",
        "leg_texts = leg.get_texts()\n",
        "# bulk-set the properties of all lines and texts\n",
        "plt.setp(leg_lines, linewidth=6)\n",
        "plt.setp(leg_texts, fontsize='x-large')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EC2RnGUIBVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Model\n",
        "saver = tf.train.Saver()\n",
        "save_path = saver.save(sess, path+\"StoredModel/v4_model.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81zM9Zx6xtm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#Restore Model\n",
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, path+\"StoredModel/v4_model.ckpt\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsFkHtIN92-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "arr_train_pred = sess.run(prediction, feed_dict={xs: df_train_feature, ys: arr_train_label, rs: 0})\n",
        "arr_valid_pred = sess.run(prediction, feed_dict={xs: df_valid_feature, ys: arr_valid_label, rs: 0})\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu0ZYmxYAvmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "train_accuracy = accuracy(arr_train_label, arr_train_pred)\n",
        "print(\"train_accuracy = \", train_accuracy*100,\"%\")\n",
        "valid_accuracy = accuracy(arr_valid_label, arr_valid_pred)\n",
        "print(\"valid_accuracy = \", valid_accuracy*100,\"%\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS6p12DdSShB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}